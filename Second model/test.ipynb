{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import argparse\n",
    "from keras.models import model_from_json, load_model\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import pdb\n",
    "\n",
    "\n",
    "class QuadPredictor():\n",
    "    def __init__(self, model_path, type_model, encoder):\n",
    "        \"\"\"Constructor method\n",
    "        \"\"\"\n",
    "        # initial configuration\n",
    "        self.max_output = False\n",
    "        self.print_approx = True\n",
    "        self.typeModel = type_model\n",
    "        self.ind_to_label_quad = {0: 'Q1 (A+V+)', 1: 'Q2 (A+V-)', 2: 'Q3 (A-V-)', 3: 'Q4 (A-V+)'}\n",
    "        self.ind_to_label_arou = {0: 'A-', 1: 'A+'}\n",
    "        self.ind_to_label_vale = {0: 'V-', 1: 'V+'}\n",
    "        self.sampling_rate = 16000\n",
    "        path_model_load = os.path.join(model_path)\n",
    "\n",
    "        # load models\n",
    "        j_f, w_f = self.model_selector(path_model_load)\n",
    "        self.model = self.load_pretrained_model(j_f, w_f)\n",
    "\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def predict_sound(self,input_file):\n",
    "        # extract spectrogram\n",
    "        spec_array = self.create_spectrogram(input_file)\n",
    "        print('*************\\nCalculating output for file:', input_file)\n",
    "        # predict!\n",
    "        self.format_input = input_file.split('.')[-1]\n",
    "\n",
    "#         out_file = os.path.join(out_dir, input_file.split('/')[-1].split('.')[0])\n",
    "\n",
    "        return self.predict_and_save(self.model, spec_array)\n",
    "       \n",
    "      \n",
    "    def model_selector(self, path):\n",
    "        \"\"\" This method selects the weights and structure of the network\n",
    "        \"\"\"\n",
    "        from os import listdir\n",
    "        from os.path import isfile, join\n",
    "        files = [ join(path, f) for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "\n",
    "        if self.typeModel == \"hdf5\":\n",
    "            weights_filename = [_ for _ in files if _.endswith('.hdf5')][0]\n",
    "        else:\n",
    "            print(files)\n",
    "            weights_filename = [_ for _ in files if _.endswith('.h5')][0]\n",
    "        json_filename = [_ for _ in files if _.endswith('.json')][0]\n",
    "        return json_filename, weights_filename\n",
    "\n",
    "\n",
    "    def load_pretrained_model(self, json_file, weight_file):\n",
    "        \"\"\" This method loads the pretrained models, loads the \n",
    "        weights and adds the new layers\"\"\"\n",
    "        # load model\n",
    "        j_f = open(json_file, 'r')\n",
    "        loaded_model = j_f.read()\n",
    "        j_f.close()\n",
    "        model = model_from_json(loaded_model)\n",
    "        # load weights\n",
    "        model = load_model(weight_file)\n",
    "        return model\n",
    "    \n",
    "    def predict(self, sound_path):\n",
    "        # Zero Crossing Rate\n",
    "        def zcr(data, frame_length=2048, hop_length=512):\n",
    "            zcr = librosa.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "            return np.squeeze(zcr)\n",
    "        #RMS Energy\n",
    "        def rmse(data, frame_length=2048, hop_length=512):\n",
    "            rmse = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "            return np.squeeze(rmse)\n",
    "        #MFCC\n",
    "        def mfcc(data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n",
    "            mfcc_feature = librosa.feature.mfcc(y=data, sr=sr)\n",
    "            return np.squeeze(mfcc_feature.T) if not flatten else np.ravel(mfcc_feature.T)\n",
    "\n",
    "        def extract_features(data, sr, frame_length=2048, hop_length=512):\n",
    "            result = np.array([])\n",
    "            result = np.hstack((result,\n",
    "                                zcr(data, frame_length, hop_length),\n",
    "                                rmse(data, frame_length, hop_length),\n",
    "                                mfcc(data, sr, frame_length, hop_length)\n",
    "                                            ))\n",
    "            return result\n",
    "\n",
    "        def noise(data,noise_rate=0.015):\n",
    "            noise_amp = noise_rate*np.random.uniform()*np.amax(data)\n",
    "            data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "            return data\n",
    "\n",
    "        def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "            return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "\n",
    "        def get_features(path):\n",
    "            #duration, offset \n",
    "            data, sample_rate = librosa.load(path, duration = 2.5)\n",
    "            \n",
    "            res1 = extract_features(data,sample_rate)\n",
    "            result = np.array(res1)\n",
    "            \n",
    "            noise_data = noise(data)\n",
    "            res2 = extract_features(noise_data,sample_rate)\n",
    "            result = np.vstack((result, res2)) \n",
    "            \n",
    "            data_pitch = pitch(data, sample_rate)\n",
    "            res3 = extract_features(data_pitch,sample_rate)\n",
    "            result = np.vstack((result, res3)) \n",
    "            \n",
    "            data_noise_pitch = noise(data_pitch)\n",
    "            res4 = extract_features(data_noise_pitch,sample_rate)\n",
    "            result = np.vstack((result, res4)) \n",
    "            \n",
    "            return result\n",
    "\n",
    "        disassembly_data = get_features(sound_path)\n",
    "        predict = self.model.predict(disassembly_data)\n",
    "        return self.encoder.inverse_transform(predict)\n",
    "\n",
    "\n",
    "\n",
    "def predict_predictor(model_path, mode ,features_path):\n",
    "    # instanciate predictor\n",
    "    Features = pd.read_csv(features_path)\n",
    "    Y = Features['Emotions'].values\n",
    "    encoder = OneHotEncoder()\n",
    "    Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "    return QuadPredictor(model_path, mode, encoder)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./model/model_json.json', './model/scaler.pkl', './model/SER_model.h5']\n"
     ]
    }
   ],
   "source": [
    "model = predict_predictor('./model/', 'h5' ,'./features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['angry'],\n",
       "       ['angry'],\n",
       "       ['disgust'],\n",
       "       ['angry']], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"./test/test.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c96ba7ee31979eb9a438c632eab3fb602e6944f4dfb08d88ff604105648beb03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
